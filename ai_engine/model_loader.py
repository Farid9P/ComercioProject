# ai_engine/model_loader.py
import os
import joblib
import json
from sklearn.feature_extraction.text import TfidfVectorizer

# ¬°Importante! Necesitamos la misma funci√≥n de limpieza para entrenar
# que la que usamos para las consultas.
from ai_engine.ai_utils import limpiar_texto 

MODEL_PATH = "models/vectorizer_es.joblib"
# --- ¬°CAMBIO! Apuntar al archivo JSON principal y correcto ---
DATABASE_PATH = "news_scrapers/noticias_partidos.json"


def _load_json_database(archivo=DATABASE_PATH):
    """
    Carga la base de datos de noticias desde el archivo JSON principal.
    """
    if not os.path.exists(archivo):
        print(f"Advertencia: No se encontr√≥ {archivo} para entrenar el vectorizador.")
        return []
    
    try:
        with open(archivo, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Asegurarse de que los datos sean una lista de art√≠culos (los valores del dict)
        if isinstance(data, dict):
            return list(data.values())
        elif isinstance(data, list):
            # Si por alguna raz√≥n se guard√≥ como lista, usarla directamente
            return data
        else:
            print(f"Error: {archivo} tiene un formato desconocido.")
            return []
            
    except json.JSONDecodeError:
        print(f"Error: El archivo {archivo} est√° corrupto o vac√≠o.")
        return []
    except Exception as e:
        print(f"Error cargando {archivo}: {e}")
        return []

def _crear_corpus_entrenamiento():
    """
    Lee todas las noticias de la base de datos JSON y las convierte en
    un gran corpus de texto para entrenar el modelo TF-IDF.
    """
    print("‚öôÔ∏è  Creando corpus de entrenamiento desde la base de datos JSON...")
    noticias_db = _load_json_database()

    if not noticias_db:
        print("‚ö†Ô∏è  El JSON est√° vac√≠o. El vectorizador no puede ser entrenado.")
        # Devolver lista vac√≠a. load_vectorizer manejar√° esto.
        return []

    corpus_base = []
    
    for n in noticias_db:
        if not isinstance(n, dict):
            continue # Omitir items que no sean diccionarios
            
        # --- ¬°INICIO DE LA CORRECCI√ìN! ---
        # Forzar que 'titulo', 'teaser' y 'contenido_full' sean strings, no None.
        
        titulo = n.get('title') or '' 
        
        data = n.get('data', {})
        if data is None: # Comprobar si 'data' es null
            data = {}
            
        teaser = data.get('teaser') or ''
        
        # Incluir el contenido completo de los otros scrapers (RPP, TV Peru, etc.)
        contenido_full = n.get('contenido_full', '') or ''
        
        # Combinar todo el texto disponible
        texto_a_limpiar = titulo + " " + teaser + " " + contenido_full
        # --- FIN DE LA CORRECCI√ìN! ---

        if texto_a_limpiar.strip():
            corpus_base.append(limpiar_texto(texto_a_limpiar))
            
    print(f"‚úÖ Corpus creado con {len(corpus_base)} art√≠culos.")
    return corpus_base

def load_vectorizer():
    """
    Carga (o crea si no existe) un vectorizador TF-IDF entrenado con
    TODAS las noticias de la base de datos JSON.
    """
    os.makedirs("models", exist_ok=True)

    if os.path.exists(MODEL_PATH):
        try:
            vectorizer = joblib.load(MODEL_PATH)
            print("‚úÖ Vectorizer cargado correctamente desde models/vectorizer_es.joblib")
            return vectorizer
        except Exception as e:
            print(f"Error cargando vectorizer: {e}")
            print("‚öôÔ∏è  Se crear√° uno nuevo desde cero.")

    # --- Creaci√≥n del Nuevo Vectorizador ---
    
    # 1. Crear el corpus desde el JSON
    corpus_base = _crear_corpus_entrenamiento()
    
    # Si el corpus est√° vac√≠o, no podemos entrenar.
    if not corpus_base:
        print("üö® ERROR CR√çTICO: No hay datos en el corpus para entrenar el vectorizador.")
        # Lanzar una excepci√≥n que main.py pueda capturar
        raise ValueError("Corpus de entrenamiento vac√≠o. Ejecuta los scrapers primero.")

    # 2. Vectorizador en espa√±ol
    vectorizer = TfidfVectorizer(
        lowercase=True,     # Ya est√° en min√∫sculas por 'limpiar_texto'
        analyzer="word",
        stop_words=None,    # Podr√≠amos a√±adir 'stop_words' en espa√±ol en el futuro
        max_features=5000   # Limitar vocabulario
    )

    try:
        # 3. Entrenar el vectorizador
        print("üß†  Entrenando nuevo vectorizer TF-IDF... (Esto puede tardar un momento)")
        vectorizer.fit(corpus_base)
        
        # 4. Guardar el modelo entrenado
        joblib.dump(vectorizer, MODEL_PATH)
        print("‚úÖ Nuevo vectorizer TF-IDF inteligente creado y guardado.")
    except Exception as e:
        print(f"Error fatal al entrenar el vectorizer: {e}")
        return None

    return vectorizer

if __name__ == "__main__":
    print("Demo model_loader ‚Äî creando/asegurando vectorizer TF-IDF...")
    vectorizer = load_vectorizer()
    if vectorizer and hasattr(vectorizer, "get_feature_names_out"):
        print("Vectorizer listo ‚úÖ")
        vocab = vectorizer.get_feature_names_out()
        print("Ejemplo de palabras del vocabulario:", list(vocab)[100:110])
    else:
        print("No se pudo cargar o entrenar el vectorizador.")